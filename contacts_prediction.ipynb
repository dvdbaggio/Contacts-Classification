{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vvk9fWsw2k-c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, matthews_corrcoef, balanced_accuracy_score, average_precision_score, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kqve4GHx2ntF",
        "outputId": "8cfd2c33-6d03-48f6-d2b4-a2b15d59ace6"
      },
      "outputs": [],
      "source": [
        "# CHECK CUDA\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0KiFdFm3t4L"
      },
      "source": [
        "# Mount Drive and Load Data\n",
        "\n",
        "To create the training dataset, upload the `features_ring` folder to your personal drive, and update the path accordingly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mQmSILF27p-",
        "outputId": "76c342b7-7eb0-4ddd-aab2-89d363d5b490"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = 'drive/MyDrive'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlCnjfzo3Q1M",
        "outputId": "d6099017-24fc-4398-998f-d3d84e46c948"
      },
      "outputs": [],
      "source": [
        "# path = \"/Users/sebastianosanson/Development/Contacts-Classification/\"\n",
        "cache_file = os.path.join(path, 'features_ring_df.pkl')\n",
        "\n",
        "if os.path.exists(cache_file):\n",
        "    df = pd.read_pickle(cache_file)\n",
        "    print(\"Loaded cached DataFrame!\")\n",
        "else:\n",
        "    dir = os.path.join(path, 'features_ring')\n",
        "    df = pd.DataFrame()\n",
        "    for file in os.listdir(dir):\n",
        "        if file.endswith('.tsv'):\n",
        "            df_temp = pd.read_csv(os.path.join(dir, file), sep='\\t')\n",
        "            df = pd.concat([df, df_temp])\n",
        "    df.to_pickle(cache_file)\n",
        "    print(\"Processed and saved DataFrame!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpwC7Qb0_qqS"
      },
      "source": [
        "## Dataset creation\n",
        "\n",
        "Add the label unclassified, fill with the mean off the column `None` value and encode as integer the secondary structures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMB2nOq4tVDD"
      },
      "outputs": [],
      "source": [
        "#### Droppa il primo caso e tiene il secondo con HBOND e VDW\n",
        "\n",
        "#columns_to_check = df.columns[:-1]\n",
        "#df_copy = df.copy()\n",
        "#df = df.drop_duplicates(subset=columns_to_check, keep='last')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZI0HRXu4JUO",
        "outputId": "abb208cf-9b06-4d1d-a41a-579b21c3f6b3"
      },
      "outputs": [],
      "source": [
        "# Labelling None values on column 'Interaction' with a proper label\n",
        "df['Interaction'] = df['Interaction'].fillna('Unclassified')\n",
        "interaction_counts = df['Interaction'].value_counts()\n",
        "print(interaction_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKd3909m8NPR",
        "outputId": "34e405b2-c0a4-4dd7-bcb3-509dfe0087c4"
      },
      "outputs": [],
      "source": [
        "contact_dict = {\n",
        "    \"HBOND\": 0,\n",
        "    \"VDW\": 1,\n",
        "    \"PIPISTACK\": 2,\n",
        "    \"IONIC\": 3,\n",
        "    \"PICATION\": 4,\n",
        "    \"SSBOND\": 5,\n",
        "    \"PIHBOND\": 6,\n",
        "    \"Unclassified\": 7\n",
        "}\n",
        "\n",
        "# Apply the mapping to create numerical labels\n",
        "y = df['Interaction'].replace(contact_dict)\n",
        "X = df[['s_ss8','s_rsa', 's_phi', 's_psi', 's_a1', 's_a2', 's_a3', 's_a4', 's_a5', 's_3di_state', 's_3di_letter',\n",
        "        't_ss8', 't_rsa', 't_phi', 't_psi', 't_a1', 't_a2', 't_a3', 't_a4', 't_a5', 't_3di_state', 't_3di_letter']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQIaPT2B8VR8"
      },
      "outputs": [],
      "source": [
        "# Encode categorical features\n",
        "le = LabelEncoder()\n",
        "X['s_ss8_encoded'] = le.fit_transform(X['s_ss8'])\n",
        "X['t_ss8_encoded'] = le.fit_transform(X['t_ss8'])\n",
        "X = X.drop(columns=['s_ss8', 't_ss8', 's_3di_letter', 't_3di_letter'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VKHqZHCsmbp",
        "outputId": "064e5f20-be8a-4882-9415-1777a899ecc4"
      },
      "outputs": [],
      "source": [
        "# Count total missing values per column\n",
        "missing_per_column = X.isna().sum()\n",
        "missing_columns = missing_per_column[missing_per_column > 0]\n",
        "print(\"Missing values per column:\\n\", missing_columns)\n",
        "\n",
        "total_missing = X.isna().sum().sum()\n",
        "print(f\"\\nTotal missing values: {total_missing}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thDFe8_FmLmO"
      },
      "outputs": [],
      "source": [
        "# Fill None values with the mean of the values of that column\n",
        "X = X.apply(lambda x: x.fillna(x.mean()) if x.dtype.kind in 'biufc' else x)\n",
        "\n",
        "total_missing = X.isna().sum().sum()\n",
        "print(f\"Total missing values, after refilling: {total_missing}\\n\")\n",
        "\n",
        "print(X.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdZtIyKWHjOY"
      },
      "source": [
        "## Feature engineering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5Lzdi75M3Sx"
      },
      "source": [
        "### `a5` product\n",
        "\n",
        "The `a5` feature measures the eletrostatic charge of the amino acids.\n",
        "\n",
        "This new engineered features, computed as `s_a5 * t_a5`, is a good indicator for mainly predicting **IONIC** bond, it measures the residues' charge: A positively charged residue (K, R have high positive a5) interacts with a negatively charged one (D, E have high negative a5). The product will be a large negative number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbPravNWUQuN",
        "outputId": "364c10ef-523e-42e3-d637-9c2bfacaf039"
      },
      "outputs": [],
      "source": [
        "X['a5_product'] = np.multiply(X['s_a5'], X['t_a5'])\n",
        "print(X.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRlTGUH4M3Sy"
      },
      "source": [
        "### `a1` product\n",
        "\n",
        "This new engineered features, computed as `s_a1 * t_a1`, is a good indicator for mainly predicting **VDW** and  bond, it measures polarity:\n",
        "* A large positive product means either both are hydrophobic (- * - = +) or both are hydrophilic (+ * + = +).\n",
        "* When combined with low RSA, a large positive a1_product strongly suggests a VDW interaction between two buried, hydrophobic residues.\n",
        "* When combined with high RSA, it suggests a polar surface interaction, likely HBOND."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq_NqEFrebnq",
        "outputId": "603a32ec-9eaa-44f5-94fb-8df4738e5a68"
      },
      "outputs": [],
      "source": [
        "X['a1_product'] = np.multiply(X['s_a1'], X['t_a1'])\n",
        "print(X.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owdmfRBiM3Sy"
      },
      "source": [
        "### `rsa` sum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scaling features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmeFE-sB8ik1"
      },
      "outputs": [],
      "source": [
        "# Scale all features to the range [0, 1]\n",
        "minmax = MinMaxScaler()\n",
        "X_scaled = minmax.fit_transform(X)\n",
        "input_dim = X_scaled.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1wAsZMbGtb-"
      },
      "outputs": [],
      "source": [
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X_scaled, y,\n",
        "    stratify=y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val,\n",
        "    stratify=y_train_val,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Convert data to numpy arrays\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_val = np.array(X_val)\n",
        "y_val = np.array(y_val)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC_IzZzN-RCS"
      },
      "source": [
        "# SMOTE Oversampling\n",
        "## Choose whether to run SMOTE from scratch (time-consuming) or load the provided `.npy` files containing a precomputed SMOTE run.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpSuRISl_EJv"
      },
      "source": [
        "## 1 - Run SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD7lJQMf-fqb",
        "outputId": "30991516-0463-471e-e8e9-e6e4e6a04ee7"
      },
      "outputs": [],
      "source": [
        "class_distribution = Counter(y_train)\n",
        "for label in sorted(class_distribution):\n",
        "    print(f\"{label}: {class_distribution[label]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bCsNjPW-oHd",
        "outputId": "7922581c-8a49-4f28-cce9-692195c4008b"
      },
      "outputs": [],
      "source": [
        "sampling_strategy = {\n",
        "    0: 675794,  # HBOND\n",
        "    1: 471719,  # VDW\n",
        "    2: 24501,  # PIPISTACK\n",
        "    3: 22650,  # IONIC\n",
        "    4: 20000,  # PICATION\n",
        "    5: 10000,  # SSBOND\n",
        "    6: 10000,  # PIHBOND\n",
        "    7: 697310   # Unclassified\n",
        "}\n",
        "\n",
        "oversample = SMOTE(sampling_strategy=sampling_strategy, random_state=42)\n",
        "\n",
        "# Fit and resample the training data\n",
        "X_train_bal, y_train_bal = oversample.fit_resample(X_train, y_train)\n",
        "\n",
        "# Verify the resampled data\n",
        "print('\\nResampled y_train_bal distribution')\n",
        "for label in sorted(Counter(y_train_bal)):\n",
        "    print(f\"{label}: {Counter(y_train_bal)[label]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsSjlxSq_F--"
      },
      "source": [
        "## 2 - LOAD Existing data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbcbiqTy_Ng4"
      },
      "outputs": [],
      "source": [
        "# X_bal = np.load(path + '/X_bal-SMOTE22.npy')\n",
        "# y_bal = np.load(path + '/y_bal-SMOTE22.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlhOIF3-Z4Mz"
      },
      "outputs": [],
      "source": [
        "# print('Original y_train distribution:', Counter(y_train))\n",
        "# print('Resampled y_bal distribution:', Counter(y_bal))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UTa0UxrMn8R"
      },
      "outputs": [],
      "source": [
        "# # Count the class in X_bal\n",
        "# unique_values, counts = np.unique(y_bal, return_counts=True)\n",
        "# print(dict(zip(unique_values, counts)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToWwXktbB5zp"
      },
      "outputs": [],
      "source": [
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CurAq5HD0D5"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVHJfZ2tO0VR"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeBnnZXla1Dt"
      },
      "outputs": [],
      "source": [
        "def feature_importance(model, interaction_type):\n",
        "  # Estrai le importanze delle feature\n",
        "  importance = model.get_score(importance_type='weight')  # 'weight', 'gain', or 'cover'\n",
        "  # UPDATE WITH NEW ENGINEERED FEATURES\n",
        "  feature_names = [\n",
        "      's_ss8','s_rsa', 's_phi', 's_psi', 's_a1', 's_a2', 's_a3', 's_a4', 's_a5', 's_3di_state',\n",
        "          't_ss8', 't_rsa', 't_phi', 't_psi', 't_a1', 't_a2', 't_a3', 't_a4', 't_a5', 't_3di_state',]\n",
        "  # Ordinare le feature per importanza\n",
        "  # Create a mapping from old keys to new feature names\n",
        "  key_mapping = {f'f{i}': feature_names[i] for i in range(len(feature_names))}\n",
        "\n",
        "  # Replace keys in the importance dictionary\n",
        "  mapped_importance = {key_mapping.get(key, key): value for key, value in importance.items()}\n",
        "\n",
        "  # Sort the features by importance\n",
        "  sorted_importance = sorted(mapped_importance.items(), key=lambda x: x[1], reverse=True)\n",
        "  features, scores = zip(*sorted_importance)\n",
        "\n",
        "  # Visualizza l'importanza delle feature\n",
        "  plt.figure(figsize=(10, 8))\n",
        "  plt.barh(features, scores)\n",
        "  plt.xlabel('Importance Score')\n",
        "  plt.title('Feature Importance for ' + str(interaction_type) + ' interaction')\n",
        "  plt.gca().invert_yaxis()  # Per visualizzare la feature piÃ¹ importante in cima\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHMWNnW7a4At"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(y_test, y_pred, y_pred_prob):\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  print(f'Accuracy: {accuracy:.4f}')\n",
        "  balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "  print(f'Balanced Accuracy: {balanced_acc:.4f}')\n",
        "  auc_roc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr')\n",
        "  print(f'AUC-ROC: {auc_roc:.4f}')\n",
        "  mcc = matthews_corrcoef(y_test, y_pred)\n",
        "  print(f'Matthews Correlation Coefficient: {mcc:.4f}')\n",
        "  average_precision = average_precision_score(y_test, y_pred_prob, average='weighted')\n",
        "  print(f'Average Precision Score: {average_precision:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ER2i5T5a-Du"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_test, y_pred, labels, interaction_type):\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  labels = sorted(contact_dict.keys(), key=lambda x: contact_dict[x])  # Sort by dict values\n",
        "  cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "\n",
        "  #plot\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "  plt.xlabel('Predicted Labels')\n",
        "  plt.ylabel('True Labels')\n",
        "  plt.title(f'Confusion Matrix for {interaction_type} interaction')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYjlXkh8O4hw"
      },
      "source": [
        "### Train loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SRcDIHINM3S1",
        "outputId": "24c39e3c-fcbf-422d-b2ed-a7e1b637e3de"
      },
      "outputs": [],
      "source": [
        "# Create arrays to store models and predictions\n",
        "models = []\n",
        "all_class_predictions = np.zeros((len(y_test), len(np.unique(y_train)))) \n",
        "\n",
        "# For each class, train a binary classifier\n",
        "for num_class in range(len(np.unique(y_train))):  \n",
        "    print(f'Training classifier for Class {num_class}')\n",
        "\n",
        "    # Create binary labels for ALL training examples\n",
        "    # 1 for current class, 0 for all other classes\n",
        "    y_train_binary = (y_train_bal == num_class).astype(int) \n",
        "    y_val_binary = (y_val == num_class).astype(int)\n",
        "\n",
        "    # Binary labels for test data\n",
        "    y_test_binary = (y_test == num_class).astype(int)\n",
        "\n",
        "    # Create DMatrix objects\n",
        "    dtrain = xgb.DMatrix(X_train_bal, label=y_train_binary)\n",
        "    dval = xgb.DMatrix(X_val, label=y_val_binary)\n",
        "    dtest = xgb.DMatrix(X_test, label=y_test_binary)\n",
        "\n",
        "    # Counte num positive/negative examples for this class\n",
        "    pos_class = np.sum(y_train_binary == 1)\n",
        "    neg_class = np.sum(y_train_binary == 0)\n",
        "\n",
        "    # Train model\n",
        "    model = xgb.train(\n",
        "        params = {\n",
        "            'device': 'cuda',\n",
        "            'objective': 'binary:logistic',\n",
        "            'eval_metric': 'auc',\n",
        "            'max_depth': 10,\n",
        "            'learning_rate': 0.2,\n",
        "            'scale_pos_weight': neg_class / pos_class if pos_class > 0 else 1.0,  # Handle class imbalance\n",
        "            'seed': 42\n",
        "        },\n",
        "        dtrain=dtrain,\n",
        "        num_boost_round=2500,\n",
        "        evals=[(dval, 'validation')],\n",
        "        early_stopping_rounds=20,\n",
        "        verbose_eval=100\n",
        "    )\n",
        "\n",
        "    # Save model\n",
        "    os.makedirs(os.path.join(path, 'models'), exist_ok=True)\n",
        "    model.save_model(os.path.join(path, f'models/xgboost_model_class_{num_class}.json'))\n",
        "\n",
        "    # Store predictions for this class\n",
        "    y_pred_prob = model.predict(dtest)\n",
        "    all_class_predictions[:, num_class] = y_pred_prob\n",
        "\n",
        "    # Evaluate this binary classifier\n",
        "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "    print(f\"\\nBinary Classification Report for Class {num_class}\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test_binary, y_pred):.4f}\")\n",
        "    print(f\"Balanced Accuracy: {balanced_accuracy_score(y_test_binary, y_pred):.4f}\")\n",
        "\n",
        "    # Optional: Display feature importance for this classifier\n",
        "    feature_importance(model, num_class)\n",
        "\n",
        "    # Store the model\n",
        "    models.append(model)\n",
        "\n",
        "# Final multi-class predictions (choose class with highest probability)\n",
        "# final_predictions = np.argmax(all_class_predictions, axis=1)\n",
        "\n",
        "# Evaluate overall multi-class performance\n",
        "# print(\"\\n==== Overall Multi-class Performance ====\")\n",
        "# compute_metrics(y_test, final_predictions, all_class_predictions)\n",
        "# plot_confusion_matrix(y_test, final_predictions, np.unique(y))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "sb_project",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
