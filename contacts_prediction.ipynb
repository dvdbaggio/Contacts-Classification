{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vvk9fWsw2k-c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, matthews_corrcoef, balanced_accuracy_score, average_precision_score, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kqve4GHx2ntF",
        "outputId": "f859783c-9e9d-4cb0-cffb-9895f60dfdb1"
      },
      "outputs": [],
      "source": [
        "# CHECK CUDA\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0KiFdFm3t4L"
      },
      "source": [
        "# Mount Drive and Load Data\n",
        "\n",
        "To create the training dataset, upload the `features_ring` folder to your personal drive, and update the path accordingly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mQmSILF27p-",
        "outputId": "10bc1ef4-0c57-4f8f-a470-d926fb8184d5"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# path = 'drive/MyDrive'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlCnjfzo3Q1M",
        "outputId": "be1cc31a-5133-485b-cfe2-bee2b1c123f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded cached DataFrame!\n"
          ]
        }
      ],
      "source": [
        "path = \"/Users/sebastianosanson/Development/Contacts-Classification/\"\n",
        "cache_file = os.path.join(path, 'features_ring_df.pkl')\n",
        "\n",
        "if os.path.exists(cache_file):\n",
        "    df = pd.read_pickle(cache_file)\n",
        "    print(\"Loaded cached DataFrame!\")\n",
        "else:\n",
        "    dir = os.path.join(path, 'features_ring')\n",
        "    df = pd.DataFrame()\n",
        "    for file in os.listdir(dir):\n",
        "        if file.endswith('.tsv'):\n",
        "            df_temp = pd.read_csv(os.path.join(dir, file), sep='\\t')\n",
        "            df = pd.concat([df, df_temp])\n",
        "    df.to_pickle(cache_file)\n",
        "    print(\"Processed and saved DataFrame!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpwC7Qb0_qqS"
      },
      "source": [
        "## Dataset creation\n",
        "\n",
        "Add the label unclassified, fill with the mean off the column `None` value and encode as integer the secondary structures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMB2nOq4tVDD"
      },
      "outputs": [],
      "source": [
        "#### Droppa il primo caso e tiene il secondo con HBOND e VDW\n",
        "\n",
        "#columns_to_check = df.columns[:-1]\n",
        "#df_copy = df.copy()\n",
        "#df = df.drop_duplicates(subset=columns_to_check, keep='last')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZI0HRXu4JUO",
        "outputId": "17e107cf-c225-451d-a736-ab8168207ca4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Interaction\n",
            "Unclassified    1089547\n",
            "HBOND           1055929\n",
            "VDW              737061\n",
            "PIPISTACK         38283\n",
            "IONIC             35391\n",
            "PICATION           8885\n",
            "SSBOND             2100\n",
            "PIHBOND            1790\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Labelling None values on column 'Interaction' with a proper label\n",
        "df['Interaction'] = df['Interaction'].fillna('Unclassified')\n",
        "interaction_counts = df['Interaction'].value_counts()\n",
        "print(interaction_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKd3909m8NPR",
        "outputId": "ea696891-3cbe-44cc-cc41-ca6def2117db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/ts/jhrtqcqd6xl3s86wsbgd3fdc0000gn/T/ipykernel_17016/1592439739.py:13: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  y = df['Interaction'].replace(contact_dict)\n"
          ]
        }
      ],
      "source": [
        "contact_dict = {\n",
        "    \"HBOND\": 0,\n",
        "    \"VDW\": 1,\n",
        "    \"PIPISTACK\": 2,\n",
        "    \"IONIC\": 3,\n",
        "    \"PICATION\": 4,\n",
        "    \"SSBOND\": 5,\n",
        "    \"PIHBOND\": 6,\n",
        "    \"Unclassified\": 7\n",
        "}\n",
        "\n",
        "# Apply the mapping to create numerical labels\n",
        "y = df['Interaction'].replace(contact_dict)\n",
        "X = df[['s_ss8','s_rsa', 's_phi', 's_psi', 's_a1', 's_a2', 's_a3', 's_a4', 's_a5', 's_3di_state', 's_3di_letter',\n",
        "        't_ss8', 't_rsa', 't_phi', 't_psi', 't_a1', 't_a2', 't_a3', 't_a4', 't_a5', 't_3di_state', 't_3di_letter']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JQIaPT2B8VR8"
      },
      "outputs": [],
      "source": [
        "# Encode categorical features\n",
        "le = LabelEncoder()\n",
        "X['s_ss8_encoded'] = le.fit_transform(X['s_ss8'])\n",
        "X['t_ss8_encoded'] = le.fit_transform(X['t_ss8'])\n",
        "X = X.drop(columns=['s_ss8', 't_ss8', 's_3di_letter', 't_3di_letter'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VKHqZHCsmbp",
        "outputId": "95b95e00-d790-4279-b958-099683c400b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values per column:\n",
            " s_rsa             63\n",
            "s_phi          17807\n",
            "s_psi           6736\n",
            "s_3di_state    37025\n",
            "t_rsa             75\n",
            "t_phi           6167\n",
            "t_psi          21474\n",
            "t_3di_state    44036\n",
            "dtype: int64\n",
            "\n",
            "Total missing values: 133383\n"
          ]
        }
      ],
      "source": [
        "# Count total missing values per column\n",
        "missing_per_column = X.isna().sum()\n",
        "missing_columns = missing_per_column[missing_per_column > 0]\n",
        "print(\"Missing values per column:\\n\", missing_columns)\n",
        "\n",
        "total_missing = X.isna().sum().sum()\n",
        "print(f\"\\nTotal missing values: {total_missing}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "thDFe8_FmLmO"
      },
      "outputs": [],
      "source": [
        "# Fill None values with the mean of the values of that column\n",
        "X = X.apply(lambda x: x.fillna(x.mean()) if x.dtype.kind in 'biufc' else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   s_rsa  s_phi  s_psi   s_a1   s_a2   s_a3   s_a4   s_a5  s_3di_state  t_rsa  \\\n",
            "0  0.632 -1.120 -0.338 -0.591 -1.302 -0.733  1.570 -0.146         17.0  0.444   \n",
            "1  0.134 -2.310  1.325  1.357 -1.453  1.477  0.113 -0.837          0.0  0.000   \n",
            "2  0.030 -1.845  2.017 -1.239 -0.547  2.131  0.393  0.816          4.0  0.268   \n",
            "3  0.018 -1.093 -0.902  1.050  0.302 -3.656 -0.259 -3.242         17.0  0.100   \n",
            "4  0.160 -2.218  2.827 -1.239 -0.547  2.131  0.393  0.816          6.0  0.454   \n",
            "\n",
            "   t_phi  t_psi   t_a1   t_a2   t_a3   t_a4   t_a5  t_3di_state  \\\n",
            "0 -2.322  2.373  1.831 -0.561  0.533 -0.277  1.648          6.0   \n",
            "1 -1.788  2.740 -1.343  0.465 -0.862 -1.020 -0.255          4.0   \n",
            "2 -2.390  2.897  0.931 -0.179 -3.005 -0.503 -1.853          2.0   \n",
            "3 -1.088 -0.766 -0.228  1.399 -4.760  0.670 -2.647         17.0   \n",
            "4 -1.551 -0.116  1.357 -1.453  1.477  0.113 -0.837         13.0   \n",
            "\n",
            "   s_ss8_encoded  t_ss8_encoded  \n",
            "0              3              7  \n",
            "1              0              1  \n",
            "2              2              0  \n",
            "3              4              4  \n",
            "4              0              3  \n"
          ]
        }
      ],
      "source": [
        "print(X.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdZtIyKWHjOY"
      },
      "source": [
        "## Feature engineering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `a5` product\n",
        "\n",
        "This new engineered features, computed as `s_a5 * t_a5`, is a good indicator for mainly predicting **IONIC** bond: A positively charged residue (K, R have high positive a5) interacts with a negatively charged one (D, E have high negative a5). The product will be a large negative number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   s_rsa  s_phi  s_psi   s_a1   s_a2   s_a3   s_a4   s_a5  s_3di_state  t_rsa  \\\n",
            "0  0.632 -1.120 -0.338 -0.591 -1.302 -0.733  1.570 -0.146         17.0  0.444   \n",
            "1  0.134 -2.310  1.325  1.357 -1.453  1.477  0.113 -0.837          0.0  0.000   \n",
            "2  0.030 -1.845  2.017 -1.239 -0.547  2.131  0.393  0.816          4.0  0.268   \n",
            "3  0.018 -1.093 -0.902  1.050  0.302 -3.656 -0.259 -3.242         17.0  0.100   \n",
            "4  0.160 -2.218  2.827 -1.239 -0.547  2.131  0.393  0.816          6.0  0.454   \n",
            "\n",
            "   ...  t_psi   t_a1   t_a2   t_a3   t_a4   t_a5  t_3di_state  s_ss8_encoded  \\\n",
            "0  ...  2.373  1.831 -0.561  0.533 -0.277  1.648          6.0              3   \n",
            "1  ...  2.740 -1.343  0.465 -0.862 -1.020 -0.255          4.0              0   \n",
            "2  ...  2.897  0.931 -0.179 -3.005 -0.503 -1.853          2.0              2   \n",
            "3  ... -0.766 -0.228  1.399 -4.760  0.670 -2.647         17.0              4   \n",
            "4  ... -0.116  1.357 -1.453  1.477  0.113 -0.837         13.0              0   \n",
            "\n",
            "   t_ss8_encoded  a5_product  \n",
            "0              7   -0.240608  \n",
            "1              1    0.213435  \n",
            "2              0   -1.512048  \n",
            "3              4    8.581574  \n",
            "4              3   -0.682992  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ],
      "source": [
        "X['a5_product'] = np.multiply(X['s_a5'], X['t_a5'])\n",
        "print(X.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `a1` product"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `rsa` sum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### sequence distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gmeFE-sB8ik1"
      },
      "outputs": [],
      "source": [
        "# Scale all features to the range [0, 1]\n",
        "minmax = MinMaxScaler()\n",
        "X_scaled = minmax.fit_transform(X)\n",
        "input_dim = X_scaled.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "f1wAsZMbGtb-"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, stratify=y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert data to numpy arrays\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC_IzZzN-RCS"
      },
      "source": [
        "# SMOTE Oversampling\n",
        "## Choose whether to run SMOTE from scratch (time-consuming) or load the provided `.npy` files containing a precomputed SMOTE run.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpSuRISl_EJv"
      },
      "source": [
        "## 1 - Run SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD7lJQMf-fqb",
        "outputId": "329e49e5-a457-4251-841f-568e32c3db49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 844743\n",
            "1: 589649\n",
            "2: 30626\n",
            "3: 28313\n",
            "4: 7108\n",
            "5: 1680\n",
            "6: 1432\n",
            "7: 871637\n"
          ]
        }
      ],
      "source": [
        "class_distribution = Counter(y_train)\n",
        "for label in sorted(class_distribution):\n",
        "    print(f\"{label}: {class_distribution[label]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bCsNjPW-oHd",
        "outputId": "8d109bc2-dd47-40d6-92cf-825d6bdae6c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resampled y_bal distribution\n",
            "0: 844743\n",
            "1: 589649\n",
            "2: 30626\n",
            "3: 50000\n",
            "4: 30000\n",
            "5: 10000\n",
            "6: 10000\n",
            "7: 871637\n"
          ]
        }
      ],
      "source": [
        "sampling_strategy = {\n",
        "    0: 844743,  # HBOND\n",
        "    1: 589649,  # VDW\n",
        "    2: 30626,  # PIPISTACK\n",
        "    3: 50000,  # IONIC\n",
        "    4: 30000,  # PICATION\n",
        "    5: 10000,  # SSBOND\n",
        "    6: 10000,  # PIHBOND\n",
        "    7: 871637   # Unclassified\n",
        "}\n",
        "\n",
        "oversample = SMOTE(sampling_strategy=sampling_strategy, random_state=42)\n",
        "\n",
        "# Fit and resample the training data\n",
        "X_bal, y_bal = oversample.fit_resample(X_train, y_train)\n",
        "\n",
        "# Verify the resampled data\n",
        "print('\\nResampled y_bal distribution')\n",
        "for label in sorted(Counter(y_bal)):\n",
        "    print(f\"{label}: {Counter(y_bal)[label]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsSjlxSq_F--"
      },
      "source": [
        "## 2 - LOAD Existing data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbcbiqTy_Ng4"
      },
      "outputs": [],
      "source": [
        "# X_bal = np.load(path + '/X_bal-SMOTE22.npy')\n",
        "# y_bal = np.load(path + '/y_bal-SMOTE22.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlhOIF3-Z4Mz",
        "outputId": "56a759ae-8c21-4313-cbfa-888c60323446"
      },
      "outputs": [],
      "source": [
        "# print('Original y_train distribution:', Counter(y_train))\n",
        "# print('Resampled y_bal distribution:', Counter(y_bal))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UTa0UxrMn8R",
        "outputId": "395bbaab-18f9-43ca-eda8-fe5be40ffdc8"
      },
      "outputs": [],
      "source": [
        "# # Count the class in X_bal\n",
        "# unique_values, counts = np.unique(y_bal, return_counts=True)\n",
        "# print(dict(zip(unique_values, counts)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "ToWwXktbB5zp",
        "outputId": "e2d00256-a8a0-44bd-9cbb-ef688df131bf"
      },
      "outputs": [],
      "source": [
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CurAq5HD0D5"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVHJfZ2tO0VR"
      },
      "source": [
        "### Parameters & Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1NhyGAAaDPg"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'device': 'cuda',\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'auc',\n",
        "    'max_depth': 10,\n",
        "    'learning_rate': 0.2,\n",
        "    'base_score': 0.5\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "TeBnnZXla1Dt",
        "outputId": "38c105f0-282e-4b44-f4b4-b3748fe976e9"
      },
      "outputs": [],
      "source": [
        "def feature_importance(model, X_train, y_train, interaction_type):\n",
        "  # Estrai le importanze delle feature\n",
        "  importance = model.get_score(importance_type='weight')  # 'weight', 'gain', or 'cover'\n",
        "  feature_names = [\n",
        "      's_ss8','s_rsa', 's_phi', 's_psi', 's_a1', 's_a2', 's_a3', 's_a4', 's_a5', 's_3di_state',\n",
        "          't_ss8', 't_rsa', 't_phi', 't_psi', 't_a1', 't_a2', 't_a3', 't_a4', 't_a5', 't_3di_state'\n",
        "  ]# Ordinare le feature per importanza\n",
        "  # Create a mapping from old keys to new feature names\n",
        "  key_mapping = {f'f{i}': feature_names[i] for i in range(len(feature_names))}\n",
        "\n",
        "  # Replace keys in the importance dictionary\n",
        "  mapped_importance = {key_mapping.get(key, key): value for key, value in importance.items()}\n",
        "\n",
        "  # Sort the features by importance\n",
        "  sorted_importance = sorted(mapped_importance.items(), key=lambda x: x[1], reverse=True)\n",
        "  features, scores = zip(*sorted_importance)\n",
        "\n",
        "  # Visualizza l'importanza delle feature\n",
        "  plt.figure(figsize=(10, 8))\n",
        "  plt.barh(features, scores)\n",
        "  plt.xlabel('Importance Score')\n",
        "  plt.title('Feature Importance for ' + str(interaction_type) + ' interaction')\n",
        "  plt.gca().invert_yaxis()  # Per visualizzare la feature più importante in cima\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHMWNnW7a4At",
        "outputId": "639b1fa0-eed6-44e4-d4a1-31755a4b88ab"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(y_test, y_pred, y_pred_prob):\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  print(f'Accuracy: {accuracy:.4f}')\n",
        "  balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "  print(f'Balanced Accuracy: {balanced_acc:.4f}')\n",
        "  auc_roc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr')\n",
        "  print(f'AUC-ROC: {auc_roc:.4f}')\n",
        "  mcc = matthews_corrcoef(y_test, y_pred)\n",
        "  print(f'Matthews Correlation Coefficient: {mcc:.4f}')\n",
        "  average_precision = average_precision_score(y_test, y_pred_prob, average='weighted')\n",
        "  print(f'Average Precision Score: {average_precision:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "7ER2i5T5a-Du",
        "outputId": "685243b5-aa65-4a33-ad5a-4a17805f8b98"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_test, y_pred, labels, interaction_type):\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  labels = sorted(contact_dict.keys(), key=lambda x: contact_dict[x])  # Sort by dict values\n",
        "  cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "\n",
        "  #plot\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "  plt.xlabel('Predicted Labels')\n",
        "  plt.ylabel('True Labels')\n",
        "  plt.title(f'Confusion Matrix for {interaction_type} interaction')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYjlXkh8O4hw"
      },
      "source": [
        "### Train loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create arrays to store models and predictions\n",
        "models = []\n",
        "all_class_predictions = np.zeros((len(y_test), len(np.unique(y_bal))))\n",
        "\n",
        "# For each class, train a binary classifier\n",
        "for num_class in range(len(np.unique(y_bal))):\n",
        "    print(f'Training classifier for Class {num_class}')\n",
        "    \n",
        "    # Create binary labels for ALL training examples\n",
        "    # 1 for current class, 0 for all other classes\n",
        "    X_train_binary = X_bal  # Use all balanced training examples\n",
        "    y_train_binary = (y_bal == num_class).astype(int)\n",
        "    \n",
        "    # Split into train/val\n",
        "    X_train, X_val, y_train_bin, y_val_bin = train_test_split(\n",
        "        X_train_binary, \n",
        "        y_train_binary, \n",
        "        test_size=0.2, \n",
        "        random_state=42,\n",
        "        stratify=y_train_binary  # Important for imbalanced data\n",
        "    )\n",
        "    \n",
        "    # Binary labels for test data\n",
        "    y_test_binary = (y_test == num_class).astype(int)\n",
        "    \n",
        "    # Create DMatrix objects\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train_bin)\n",
        "    dval = xgb.DMatrix(X_val, label=y_val_bin)\n",
        "    dtest = xgb.DMatrix(X_test, label=y_test_binary)\n",
        "    \n",
        "    # Train model\n",
        "    model = xgb.train(\n",
        "        params, \n",
        "        dtrain, \n",
        "        num_boost_round=2500, \n",
        "        evals=[(dval, 'validation')], \n",
        "        early_stopping_rounds=20\n",
        "    )\n",
        "    \n",
        "    # Save model\n",
        "    os.makedirs(os.path.join(path, 'models'), exist_ok=True)\n",
        "    model.save_model(os.path.join(path, f'models/xgboost_model_class_{num_class}.json'))\n",
        "    \n",
        "    # Store predictions for this class\n",
        "    y_pred_prob = model.predict(dtest)\n",
        "    all_class_predictions[:, num_class] = y_pred_prob\n",
        "    \n",
        "    # Evaluate this binary classifier\n",
        "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "    print(f\"\\nBinary Classification Report for Class {num_class}\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test_binary, y_pred):.4f}\")\n",
        "    print(f\"Balanced Accuracy: {balanced_accuracy_score(y_test_binary, y_pred):.4f}\")\n",
        "    \n",
        "    # Optional: Display feature importance for this classifier\n",
        "    feature_importance(model, X_train, y_train_bin, num_class)\n",
        "    \n",
        "    # Store the model\n",
        "    models.append(model)\n",
        "\n",
        "# Final multi-class predictions (choose class with highest probability)\n",
        "# final_predictions = np.argmax(all_class_predictions, axis=1)\n",
        "\n",
        "# Evaluate overall multi-class performance\n",
        "# print(\"\\n==== Overall Multi-class Performance ====\")\n",
        "# compute_metrics(y_test, final_predictions, all_class_predictions)\n",
        "# plot_confusion_matrix(y_test, final_predictions, np.unique(y))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "sb_project",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
